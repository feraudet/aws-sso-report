#!/usr/bin/env python3
"""
Simple test script to verify the new scoring system integration.
Run from the project root directory.
"""

import os
import sys

# Add src to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "src"))


def test_config_loading():
    """Test that the YAML configuration loads correctly."""
    print("üîß Testing configuration loading...")

    try:
        import yaml

        config_path = os.path.join(
            os.path.dirname(__file__), "config", "permission_scoring_minimal.yaml"
        )

        with open(config_path, "r") as f:
            config = yaml.safe_load(f)

        # Basic validation
        assert "risk_levels" in config, "risk_levels should be in config"
        assert "services" in config, "services should be in config"
        assert "iam" in config["services"], "IAM service should be configured"

        print("‚úÖ Configuration loaded successfully")
        print(f"   Services configured: {list(config['services'].keys())}")

        # Test some critical actions
        iam_actions = config["services"]["iam"]["actions"]

        critical_actions = [
            action
            for action, details in iam_actions.items()
            if details.get("risk_level") == "critical"
        ]

        print(f"   Critical IAM actions: {len(critical_actions)}")
        print(f"   Examples: {critical_actions[:3]}")

        return True

    except Exception as e:
        print(f"‚ùå Configuration loading failed: {e}")
        return False


def test_scoring_logic():
    """Test basic scoring logic without AWS dependencies."""
    print("\nüéØ Testing scoring logic...")

    try:
        # Import the scoring config module
        from permission_scoring_config import PermissionScoringConfig

        config = PermissionScoringConfig()

        # Test cases: (action, expected_risk_level, description)
        test_cases = [
            ("kms:Decrypt", "low", "KMS Decrypt should be low risk (read-only)"),
            (
                "iam:CreateRole",
                "critical",
                "IAM CreateRole should be critical (privilege escalation)",
            ),
            ("s3:GetObject", "low", "S3 GetObject should be low risk (read-only)"),
            (
                "ec2:AuthorizeSecurityGroupIngress",
                "critical",
                "Security Group modification should be critical",
            ),
        ]

        print("   Testing action scoring with justifications:")
        for action, expected_risk, description in test_cases:
            (
                read_score,
                write_score,
                admin_score,
                actual_risk,
                justification,
            ) = config.score_action(action)

            status = "‚úÖ" if actual_risk == expected_risk else "‚ö†Ô∏è"
            print(f"   {status} {action}: {actual_risk} (expected {expected_risk})")
            print(f"      Justification: {justification}")
            print()

        # Test managed policies
        print("\n   Testing managed policy scoring:")
        policy_tests = [
            ("AdministratorAccess", "Should have high admin score"),
            ("ReadOnlyAccess", "Should have low scores"),
            ("PowerUserAccess", "Should have high admin score"),
        ]

        for policy_name, description in policy_tests:
            read_score, write_score, admin_score = config.score_managed_policy(
                policy_name
            )
            print(
                f"   ‚úÖ {policy_name}: read={read_score}, write={write_score}, admin={admin_score}"
            )

        return True

    except Exception as e:
        print(f"‚ùå Scoring logic test failed: {e}")
        return False


def test_data_models():
    """Test that data models work correctly."""
    print("\nüìä Testing data models...")

    try:
        from data_models import AccessLevel, PermissionScores, RiskLevel, Role

        # Test enum values
        assert (
            AccessLevel.READ_ONLY.value == "Read Only"
        ), "AccessLevel enum should work"
        assert RiskLevel.LOW.value == "LOW", "RiskLevel enum should work"

        # Test PermissionScores
        scores = PermissionScores(read_score=5, write_score=3, admin_score=0)
        assert scores.read_score == 5, "PermissionScores should work"

        # Test Role creation
        role = Role(
            name="TestRole",
            arn="arn:aws:sso:::permissionSet/test",
            access_level=AccessLevel.READ_ONLY,
            scores=scores,
        )

        assert role.name == "TestRole", "Role creation should work"
        assert role.risk_level == RiskLevel.LOW, "Risk level should be calculated"

        print("‚úÖ Data models working correctly")
        print(f"   Role: {role.name}")
        print(f"   Access Level: {role.access_level.value}")
        print(f"   Risk Level: {role.risk_level.value}")

        return True

    except Exception as e:
        print(f"‚ùå Data models test failed: {e}")
        return False


def main():
    """Run all tests."""
    print("üöÄ TESTING NEW SCORING SYSTEM INTEGRATION")
    print("=" * 50)

    tests = [
        test_config_loading,
        test_scoring_logic,
        test_data_models,
    ]

    passed = 0
    total = len(tests)

    for test in tests:
        if test():
            passed += 1

    print(f"\nüìä RESULTS: {passed}/{total} tests passed")

    if passed == total:
        print("\nüéâ ALL TESTS PASSED!")
        print("‚úÖ New scoring system is ready for production")
        print("‚úÖ Configuration-driven approach is working")
        print("‚úÖ Security-critical actions are properly identified")
    else:
        print(f"\n‚ùå {total - passed} tests failed")
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())
